---
title: "Team 4 - Heart Disease Detection"
author: "Claire, Bentzen, John Vincent Deniega, Ravita Kartawinata"
date: "`r Sys.Date()`"
format: 
    #html: 
    #    toc: true
    pdf: default
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library}
suppressPackageStartupMessages(library(caret))
library(tidyr)
library(tidyverse)
library(gt)
library(dplyr)
library(tibble)
suppressPackageStartupMessages(library(pROC))
suppressPackageStartupMessages(library(ggplot2))
library(corrplot)
```

```{r preprocess}
seed <- 123
#Ingest
data <- read.csv("heart.csv") #Change to your respective local path
```

```{r preprocess}
#Check for missing columns
missing_col <- colSums(is.na(data))
cat('No missing values found: \n')
missing_col

#Check for duplicate rows
duplicate_row <- data[duplicated(data),]
cat('Count of duplicate rows: ', nrow(duplicate_row),'\n')

data1 <- data[!duplicated(data),]
cat('NewData dimension: ',nrow(data1),'remaining rows. This is still sufficient since ncol^2 is less than #nrows\n')

#Center and scale continuous variables
pre_proc <- preProcess(data1[c("age", "trestbps", "chol", "thalach", "oldpeak")], method = c("center", "scale"))
data2 <- data1
data2[c("age", "trestbps", "chol", "thalach", "oldpeak")] <- 
  predict(pre_proc, data1[c("age", "trestbps", "chol", "thalach", "oldpeak")])

#Since "thal" is not ordinal, but effectively categorical, make dummy variables
data3 <- data2
data3$thal <- factor(data3$thal)
dummy <- dummyVars(~ thal, data = data3)
dummy_col <- predict(dummy, newdata = data3)
data3 <- cbind(data3, dummy_col)
data3$thal <- NULL # Drop the "thal" column now that we have dummy variables
cat('NewData dimension: ',nrow(data3),'remaining rows. This is still sufficient since ncol^2 is less than #nrows \n')
```

```{r EDA}
#Check column histograms for unusual distributions
ggplot(gather(data3), aes(value)) +
  geom_histogram(bins = 20) +
  facet_wrap(~key, scales = "free")
```

```{r EDA2}
# continuous predictors
cont_pred <- c('age', 'chol', 'oldpeak', 'thalach', 'trestbps')
cont_data <- data3[, cont_pred]
ex_cont_data <- data3[,!names(data3) %in% cont_pred]
# boxplots
ggplot(gather(cont_data), aes(value)) +
  geom_boxplot() +
  facet_wrap(~key, scales = "free") +
  labs(title = "Boxplots for Continuous Predictors")
```

```{r outliers}
# outlier handling
for (pred in cont_pred) {
  # identify outliers
  z_score <- scale(data3[[pred]])
  outlier <- which(abs(z_score) > 3)
  
  # remove outlier rows
  rem_outliers <- data3[-outlier, ]
}

data3 <- rem_outliers
```

```{r EDA3}
data3$target <- as.factor(data3$target)
data3$sex <- as.factor(data3$sex)
# stacked bar plot for heart disease detection in males vs females

ggplot(data3, aes(x = sex, fill = target)) +
  geom_bar() +
  labs(title = "Bar Plot of Sex by Heart Disease Detection",
       x = "Sex",
       y = "Count",
       fill = "Target") +
  scale_x_discrete(labels = c("0" = "Female", "1" = "Male")) +
  theme_minimal()
```

```{r EDA4}
data3$target <- as.factor(data3$target)
data3$thal.1 <- as.factor(data3$thal.1)
data3$thal.2 <- as.factor(data3$thal.2)
data3$thal.3 <- as.factor(data3$thal.3)

# stacked bar plot for heart disease detection in thal.1
ggplot(data3, aes(x = thal.1, fill = target)) +
  geom_bar() +
  labs(title = "Bar Plot of Thal = Normal by Heart Disease Detection",
       x = "Thal = Normal",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("0" = "Other", "1" = "Normal")) +
  theme_minimal()

# stacked bar plot for heart disease detection in thal.2
ggplot(data3, aes(x = thal.2, fill = target)) +
  geom_bar() +
  labs(title = "Bar Plot of Thal = Fixed Defect by Heart Disease Detection",
       x = "Thal = Fixed Defect",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("0" = "Other", "1" = "Fixed Defect")) +
  theme_minimal()

# stacked bar plot for heart disease detection in thal.3
ggplot(data3, aes(x = thal.3, fill = target)) +
  geom_bar() +
  labs(title = "Bar Plot of Thal = Reversible Defect by Heart Disease Detection",
       x = "Thal = Reversable Defect",
       y = "Count",
       fill = "Heart Disease") +
  scale_x_discrete(labels = c("0" = "Other", "1" = "Reversible Defect")) +
  theme_minimal()
```

```{r EDA5}
# histogram of age segmented by heart disease detection
ggplot(data3, aes(x = age, fill = target)) +
  geom_histogram(binwidth = .1, position = "stack", alpha = 0.5) +
  labs(title = "Histogram Segmented by Heart Disease Detection",
       x = "Age",
       y = "Frequency",
       fill = "Heart Disease") +
  theme_minimal()
```

```{r preprocess}
#Check for near-zero variance columns
nzv <- nearZeroVar(data3)
cat('Removed near zero predictor: ', colnames(data3)[nzv],'\n')

data4 <- data3[, -nearZeroVar(data3)]
cat('NewData dimension: ',nrow(data4),'rows', ncol(data4), 'columns\n') 
# Note: There appears to be an error in documentation where thal is actually thal+1 category
# Normal = 1
# Fixed Defect = 2
# Reversable Defect = 3
```

```{r correlation}
# remove highly correlated predictors
p_correlations <- cor(cont_data, method = "pearson")
p_highCorr <- findCorrelation(p_correlations, cutoff = .75)
p_highCorr # No continuous variables correlated > .75

ex_cont_data$sex <- as.integer(ex_cont_data$sex)
ex_cont_data$thal.1 <- as.integer(ex_cont_data$thal.1)
ex_cont_data$thal.2 <- as.integer(ex_cont_data$thal.2)
ex_cont_data$thal.3 <- as.integer(ex_cont_data$thal.3)

s_correlations <- round(cor(ex_cont_data[, !names(ex_cont_data) %in% "target"], 
                      method = "spearman"), 3)
s_highCorr <- findCorrelation(s_correlations, cutoff = .75)
data5 <- data4[, -s_highCorr]
cont_data
# correlation plot among predictor variables
p_correlations <- cor(cont_data)
c_correlations <- cor(ex_cont_data)
p_corr_plot <- corrplot(p_correlations)
c_corr_plot <- corrplot(c_correlations)
```

```{r confounders}
# logistic regression model with possible confounding predictors
confounding_model <- glm(target ~ age + sex + thal.2 + thal.3, data = data5, family = "binomial")
summary(confounding_model)
```

The low p-values for age, sex, and thal.2 indicate that these are possible confounding variables, however it does not confirm it. We have to now look at the correlation between the predictors and the target variable.

```{r conf_corr}
# correlation between possible confounders and target
data_conf_check <- data5

data_conf_check$target <- as.integer(data_conf_check$target)
data_conf_check$age <- as.integer(data_conf_check$age)
data_conf_check$sex <- as.integer(data_conf_check$sex)
data_conf_check$thal.2 <- as.integer(data_conf_check$thal.2)
data_conf_check
cor(data_conf_check[c("target", "age", "sex", "thal.2")])
```

Age and sex have a very low correlation with the target variable, so we can keep them. The correlation thal.2 has with the target variable is moderate, but not high enough to indicate that there might be significant changes to the outcome of the model if we keep it.

```{r split}
set.seed(seed)
y <- data5$target 
x <- data5[, !names(data5) %in% "target"] # Predictors only

trainingRows <- createDataPartition(y, p = .80, list = FALSE) #list of indices from training
train_y <- y[trainingRows]
test_y <- y[-trainingRows]
train_x <- x[trainingRows, ] 
test_x <- x[-trainingRows, ]
train_x <- data.frame(lapply(train_x, function(x) if(is.factor(x)) as.numeric(as.character(x)) else x))
cat('Number of training sample:', nrow(train_x), 'and test samples: ',nrow(test_x), 'number of predictors:', ncol(train_x))
```

```{r cross validation and hypertune binary classify}
# Evaluation Metric
sens_spec_harm <- function(data, lev = NULL, model = NULL) {
  sens <- sensitivity(data$pred, data$obs, positive = levels(data$obs)[1])
  spec <- specificity(data$pred, data$obs, positive = levels(data$obs)[1])
  harmonic <- (2 * sens * spec) / (sens + spec)
  c(harmonic = harmonic, sensitivity = sens, specificity = sens)
}

#sens_spec_harm <- function(data, lev = NULL, model = NULL) {
#  data$pred <- as.numeric(as.character(data$pred))
#  data$obs <- factor(data$obs)
#  sens <- sensitivity(data$pred, data$obs)
#  spec <- specificity(data$pred, data$obs)
#  harmonic <- (2 * sens * spec) / (sens + spec)
# roc_curve <- roc(data$obs, data$pred)
#  auc_value <- auc(roc_curve)
#  c(harmonic = harmonic, sensitivity = sens, specificity = sens, ROC_AUC = #auc_value)
#}

ctrl <- trainControl(method = "repeatedcv", repeats = 5,
                     summaryFunction = sens_spec_harm,
                     classProbs = TRUE,
                     savePredictions = TRUE)

tunegrid <- expand.grid(alpha = c(0,  .1,  .2, .4, .6, .8, 1),
                        lambda = seq(.01, .2, length = 10))


```

```{r model}
# Logistic Regression
levels(train_y) <- make.names(levels(train_y))
set.seed(476)
LR_model <-suppressWarnings(
  train(x = train_x, y = train_y,
           method = "glm",
           #tuneGrid = tunegrid,
           preProc = c("center", "scale"),
           metric = "sens_spec_harm",
           trControl = ctrl))
#linear discriminant
set.seed(476)
LDA_model <-suppressWarnings(
  train(x = train_x, y = train_y,
            method = "lda",
            preProc = c("center", "scale"),
            metric = "sens_spec_harm",
            trControl = ctrl))
#penalized logistic regression
set.seed(476)
PLR_model <-  suppressWarnings(
  train(x = train_x, y = train_y,
           method = "glmnet",
           tuneGrid = tunegrid,
           preProc = c("center", "scale"),
           metric = "sens_spec_harm",
           trControl = ctrl))
#nearest shrunken centroids
set.seed(476)
tunegrid <- expand.grid(threshold = seq(0, 25, length = 30))
NSC_model <-suppressWarnings(
  train(x = train_x, y = train_y,
          method = "pam",
          preProc = c("center", "scale"),
          tuneGrid = tunegrid,
          metric = "sens_spec_harm",
          trControl = ctrl))
```

```{r model-performance}
#Harmonic
LR_sens_spec <- LR_model$results$harmonic
LDA_sens_spec <- LDA_model$results$harmonic
PLR_sens_spec <- mean(PLR_model$results$harmonic)
NSC_sens_spec <- mean(NSC_model$results$harmonic)

sens_spec_values <- data.frame(
  Model = c("LogisticRegression", "LinearDiscriminant",
  "PenalizedLogisticRegression", "NearestShrunken"),
  F_Score_Sens_Spec = c(LR_sens_spec, LDA_sens_spec, 
          PLR_sens_spec, NSC_sens_spec)
)
sens_spec_values %>% arrange(desc(F_Score_Sens_Spec))

#confusion Matrix
LR_CM <- confusionMatrix(LR_model, norm="none")
LDA_CM <- confusionMatrix(LDA_model, norm="none")
PLR_CM <- confusionMatrix(PLR_model, norm="none")
NSC_CM <- confusionMatrix(NSC_model, norm="none")

#ROC-AUC  --> NEED TO CHANGE METRIC FUNCTION???????
LR_auc <- LR_model$results$ROC_AUC
LDA_auc <- LDA_model$results$ROC_AUC
PLR_auc <- mean(PLR_model$results$ROC_AUC)
NSC_auc <- mean(NSC_model$results$ROC_AUC)


Model_performance <-  data.frame(
  Model = c("LogisticRegression", "LinearDiscriminant",
  "PenalizedLogisticRegression", "NearestShrunken"),
  Accuracy = c(
      sum(diag(LR_CM$table))/ sum(LR_CM$table),
      sum(diag(LDA_CM$table))/ sum(LDA_CM$table),
      sum(diag(PLR_CM$table))/ sum(PLR_CM$table),
      sum(diag(NSC_CM$table))/ sum(NSC_CM$table)
    ),
  AUC = c(LR_auc, LDA_auc, PLR_auc, NSC_auc)
)
Model_performance
```

```{r predict}
# convert all predictors to numeric
test_x <- data.frame(lapply(test_x, function(x) if (is.factor(x)) as.numeric(as.character(x)) else x))

levels(test_y) <- make.names(levels(test_y))
              
# predict test data with each model        
test_results <- data.frame(obs = test_y, 
                           LR = predict(LR_model, test_x))

test_results$LDA <- predict(LDA_model, test_x)

test_results$PLR <- predict(PLR_model, test_x)

test_results$NSC <- predict(NSC_model, test_x)
```

```{r comparison}
# model comparison using confusion matrix
LR_CM_pred <- confusionMatrix(test_results$LR, test_results$obs, positive = "X1")
LDA_CM_pred <- confusionMatrix(test_results$LDA, test_results$obs, positive = "X1")
PLR_CM_pred <- confusionMatrix(test_results$PLR, test_results$obs, positive = "X1")
NSC_CM_pred <- confusionMatrix(test_results$NSC, test_results$obs, positive = "X1")

#ROC
LR_roc_pred <- roc(test_results$obs, as.numeric(test_results$LR))
LDA_roc_pred <- roc(test_results$obs, as.numeric(test_results$LDA))
PLR_roc_pred <- roc(test_results$obs, as.numeric(test_results$PLR))
NSC_roc_pred <- roc(test_results$obs, as.numeric(test_results$NSC))

Test_performance <-  data.frame(
  Model = c("LogisticRegression", "LinearDiscriminant",
  "PenalizedLogisticRegression", "NearestShrunken"),
  Accuracy = c(
    LR_CM_pred$overall['Accuracy'],
    LDA_CM_pred$overall['Accuracy'],
    PLR_CM_pred$overall['Accuracy'], 
    NSC_CM_pred$overall['Accuracy'] 
    ),
  AUC = c(
    LR_roc_pred$auc, LDA_roc_pred$auc,
    PLR_roc_pred$auc,NSC_roc_pred$auc
  )
)
Test_performance


```

```{r important_vars}
LR_ImpVar <- varImp(LR_model, scale = FALSE)
top5_LR_ImpVar <- LR_ImpVar$importance %>% 
  arrange(desc(Overall)) %>% slice(1:5)

LDA_ImpVar  <-  varImp(LDA_model)
importance_df <- LDA_ImpVar$importance
top5_LDA_ImpVar <- importance_df[order(-importance_df$X1), ]
top5_LDA_ImpVar <- head(top5_LDA_ImpVar["X1"],5)

PLR_ImpVar <- varImp(PLR_model)
suppressPackageStartupMessages({top5_PLR_ImpVar <- 
  PLR_ImpVar$importance %>% arrange(desc(Overall)) %>% slice(1:5)})

NSC_ImpVar <- varImp(NSC_model)
importance_df <- NSC_ImpVar$importance
top5_NSC_ImpVar <- importance_df[order(-importance_df$X1), ]
top5_NSC_ImpVar <- head(top5_NSC_ImpVar["X1"],5)


top5_ImpVar <- data.frame(
  LR_ImpVar = rownames(top5_LR_ImpVar),
  LDA_ImpVar =  rownames(top5_LDA_ImpVar),
  PLR_ImpVar =  rownames(top5_PLR_ImpVar),
  NSC_ImpVar = rownames(top5_NSC_ImpVar)
)
top5_ImpVar
```
